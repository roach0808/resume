John Thomason
Senior Python/AI/ML & Agent Specialist	NC, United State(US citizen)
thomasonjohn972@gmail.com
www.linkedin.com/in/john-thomason-9b6991366
https://john-thomason-ai.vercel.app/
+18632130426

I am an ambitious Senior AI/ML Backend Engineer, with 10 years of experience in the Software Development industry. 
My passion for Artificial Intelligence research and development ignited at its very beginning in America. Since then, I’ve been keen on architecting, designing, and implementing top-of-the-line software solutions tailored to the unique needs of businesses. 
My commitment to staying at the forefront of technological advancements has enabled me to exceed the evolving demands of the digital business landscape. 
My biggest differentiator is my expertise - based upon best practices study, a non-conventional approach that goes beyond the latest tech trends, and proven solutions that best fit business objectives. Whether we’re talking about Product Development, driving projects as a Contractor, I’m enthusiastic about delivering results that transcend expectations. 
My proficiency in AI, MLOps, and System Architecture are not just skill sets. They are components that bridge the gap between real-world solutions and advanced algorithmic strategies.
- Technical Proficiencies

Languages:	Python, JavaScript, C++, Rust, C#
Software Design Architecture:	FTI Architecture, batch serving architecture, online real-time pipeline, offline batch pipeline, asyncronous inference pipeline
AI Frameworks:	PyTorch, TensorFlow, Keras, Scikit-learn, XGBoost, langchain, Llama-index, Haystack, langGraph, AutoGen, Crew AI, Agentic Transformer
MLOps	GCP(Vertex AI, GCR, GKE, GCS, pub/sub), AWS(AWS SageMaker, Fargate, lambda, S3 bucket), Azure, W&B, DVC, Arize, Comet ML,Qwak, Databricks, MLFlow, Apache Spark
LLM:
	OpenAI, Anthropic, Azure, Llama-3,Mistral, Multi-modal LLM(TTS/STT/VST/AST), SDXL, Gemini,Vertex, Perplexity, Advanced RAG, TAG, Advanced chunking strategy
Data Science:	     Pydantic, PySpark, Pandas, Polar, Ibis, BigQuery, MCP
Fullstack Development:	     Django, Flask, FastAPI, Express.JS, Node.js, PHP, React.JS, Next.JS
Database:
	PostgreSQL, MongoDB, Aurora DB, DynamoDB, Redis, Qdrant, SnowFlake, Hopsworks, PGVector, Pinecone, Milvus
Orchestrator:	Docker Swarm, ECS, K8s, Airflow, Kubeflow, ZenML, PipeDream
ORM:	Alchemy, Peewee, Django ORM
API Design Models:	REST API, RPC, GraphQL
CI/CD:	Git, GitLab, GitHub Actions, Jenkins, Kubernetes, CircleCI
Cloud Infrastructure Tools:	Terraform, Cloudformation, CDK, Pulumi
Streaming:	Apache Kafka, AWS Flink, Bytewax, CDC pattern, RabbitMQ, GCP pub/sub
ML Optimization	TorchServe, TensorFlow Serving, Ray Serve, NVIDIA TensorRT-LLM, NVIDIA Triton 
Inference Server, ollama, llama.cpp, vllm, sglang, LitServe, TGI, KV cache 
Continuous batching, Speculative Decoding, FL(with ONNX)

- Career Experience
InsoftAI, FL, United State
Senior Machine Learning & AI-Agent Specialist	02/2023 – present
I led and developed powerful AI-Driven Platforms and ML projects, streaming business operations by integrating AI- driven systems capable of handling up to 90% of customer inquiries.  Developed Support-nGen™, a proprietary system designed to enhance customer service by efficiently managing FAQs, support tickets, and complex queries.
Also, I developed a LLM Twin, an advanced AI character that emulates individual writing/coding styles, voices, and personalities to serve as an effective writing co-pilot, facilitating brand creation by automating the writing process, generating new creative ideas, and streamlining content creation.

Designed and developed a suite of intelligent, domain-specific AI agents for healthcare, tourism, and operations, enabling multimodal interaction via WhatsApp and web interfaces. 
☑ Delivered robust capabilities such as appointment automation, medical form handling, travel logistics, and dynamic multilingual support—each powered by typo-tolerant natural language understanding and integrated backend workflows. ☑ Built a scalable orchestration system and deployed a fast, ASR-free multimodal LLM for seamless text and voice interaction, significantly improving user experience and operational efficiency.
☑ Implemented expertise in implementing a sequential request processing system with a strong emphasis on low latency,  adopting an online real-time inference deployment architecture to enhance overall performance and responsiveness.
☑ Designed cloud-service/microservice architecture by splitting the ML service into a REST API server for business logic and an optimized LLM microservice, leveraging powerful machines and various engines to enhance latency and memory usage, thereby facilitating quick adaptation of the infrastructure based on different LLM sizes.
☑ Demonstrated a comprehensive approach by integrating Graph RAG with Neo4j within the business microservice, incorporating advanced RAG techniques to optimize the pre-retrieval, retrieval, and post-retrieval steps, resulting in enhanced accuracy and improved response, implementing binay quantization solution improving RAG search to 40x faster.
☑ Utilized Opik to develop a sophisticated dashboard for monitoring complex prompt traces and implemented its Python SDK to effectively evaluate agentic and RAG applications, resulting in enhanced experiment tracking and improved performance comparisons.
☑ Implemented a highly efficient deployment strategy for the LLM microservice on AWS SageMaker, utilizing Hugging Face’s Deep Learning Containers (DLCs) to enhance model inference. This robust infrastructure supported scalable, secure, and efficient real-time predictions through critical components such as SageMaker endpoints, model configuration, and inference components. By leveraging the Text Generation Inference (TGI) engine, the system achieved superior computational efficiency via tensor and dynamic batching for leading open-source LLMs like Mistral, Llama, and Falcon, accomplished optimizing performance with flash-attention, minimizing model size through model parallelism and weight quantization, enhancing throughput with speculative decoding, continuous batching, accelerating weight loading using safetensors, and enabling real-time interactions via token streaming, culminating in a responsive and effective LLM serving solution and achieving speedups of 2-4x or more.
☑ Developed and implemented fine-tuning process with Unsloth, a high-performance library, utilizing custom kernels, accelerating training by 2-5x and significantly reducing memory usage by up to 80%. 
☑ Engineered a business microservice using FastAPI, initially deployed to AWS Elastic Kubernetes Service (EKS) or AWS Elastic Container Service (ECS), involving Dockerization of the application, pushing the Docker image to AWS ECR, and configuring the deployment, while also orchestrating ML pipelines using ZenML / Airflow, storing and versioning ML pipelines as outputs, and attaching metadata to artifacts for better observability.
☑ Utilized advanced profiling tools to identify costly lines of code and uncover performance blind spots in local programs and Kubernetes clusters running on Linux, successfully optimizing CPU, GPU, and I/O performance, which led to an estimated 20% reduction in infrastructure costs.
☑ By integrating Ragas’s strengths in production monitoring and LLM-assisted metrics with ARES’s configurable evaluation process and classifier-based assessments, enhanced evaluation capabilities, achieving quick iterations and in-depth, customized evaluations that significantly improve performance outcomes.
☑ Designed a clean backend–frontend architecture with FastAPI, built a web API using FastAPI and add WebSocket support agent can respond in real time.
☑ Exhibited strong leadership abilities by mentoring junior staff, enhancing their communication skills, and encouraging professional development.
CoreWeave, Livingston, NJ
Senior AI/MLOps Engineer & Agent Developer	10/2019 – 12/2022
I specialize in architecting, designing, and implementing cutting-edge software solutions tailored to meet diverse business needs. 
I led design and implementation of a multimodal AI healthcare multi-agent system to automate multi-specialist medicaldiagnosis. Expanded the system's capabilities by integrating additional medical specialties, including dermatology and nephrology, while establishing seamless connections with electronic health record (EHR) systems to enable direct report retrieval and analysis. I trained AI model using custom-trained algorithms to enhance the accuracy of medical analyses,significantly improving diagnostic efficiency and collaboration among specialists. Also, developed a robust architecture comprising medical report extraction, specialist AI agents for multi-perspective analysis, and a multidisciplinary team agent to aggregate insights, ultimately generating comprehensive multidisciplinary diagnoses stored as text files.
I engineered a real-time personalized recommender system for H&M fashion articles using the 4-stage recommender architecture and a two-tower model design architecture, leveraging the Hopsworks AI Lakehouse.
Also, implemented an Intelligent Financial Advisor that provides real-time insights and personalized recommendations to users based on their financial goals and market conditions. Built an ML system for forecasting hourly energy consumption levels across Denmark and built healthcare insurance fraud identification using PCA anomaly detection using unsupervised anomalous outlier techniques on a minimal set of metrics made available in the CMS Medicare inpatient claims.
☑ Designed 4-stage architecture to build a system that can handle recommendations from a catalog of millions of
items and two-tower model, a flexible neural network design that creates embeddings for users and items and optimized deploying ML models using Auto scaling, model optimization/parallelism/quantization, implementing a strategy similar to what TikTok employs for short videos, which will be applied to H&M retail items.
☑ Enhanced recommender systems by integrating advanced evaluation metrics such as NDCG, Precision@K, Recall@K, and Mean Reciprocal Rank (MRR), providing nuanced insights into model performance and user relevance, ultimately improving user satisfaction and engagement.
☑ Deployed real-time recommendations using Hopsworks Serverless and KServe, a runtime engine for serving predictive and generative ML models on Kubernetes, which simplifies autoscaling, networking, health checks, and server configuration while providing advanced features like GPU autoscaling and canary rollouts; through KServe, I successfully implemented two distinct services— the query encoder service and the ranking service—resulting in improved model performance and responsiveness in production.
☑ A real-time streaming pipeline that listens to financial news, cleans & embeds the documents, and loads them
to a vector DB. 
☑ A fine-tuning pipeline (deployed as a serverless continuous training) that fine-tunes an LLM on financial data
using QLoRA, monitors the experiments using an experiment tracker, and saves the best model to a model registry. 
☑ An inference pipeline built in LangChain, LangGraph(multi-agents) and LangSmith (deployed as a serverless RESTful API and monitoring) that loads the fine-tuned LLM from the model registry and answers financial questions using RAG/TAG (using the vector DB populated with financial news in real-time) .
☑ By addressing the limitations of traditional RAG with KAG, achieved over 94% accuracy in popular science queries and 93% in interpreting medical indicators, showed similarly impressive results, with precision rates of 91.6% and recall rates of 71.8% — a significant improvement over traditional RAG methods.
☑ I adopted MLOps best practices, including Infrastructure as Code (IaC), CI/CD, monitoring, experiment tracking, and model registries, ensuring the system is reproducible, testable, and trackable and deployed a scalable and cost-effective asynchronous batch architecture on AWS ECS and SQS, dynamically scaling based on job volume and achieving a 52% reduction in AWS costs.
Kensho, Massachusetts, United State
Backend-heavy AI Developer	09/2017 – 09/2019
I worked on a TTS and STT solution, exposing it as an API that accurately clone voices from a short audio clip, significantly enhancing user experience in voice synthesis applications.
☑ Optimized training processes using distributed computing techniques, reducing training time by 5%.
☑ Collaborated with research teams to implement cutting-edge algorithms, enhancing the company's AI
capabilities.
☑ I built an inference pipleline in LangChain as a serverless RESTful API, enabling real-time financial question answering using RAG/TAG, significantly improving user engagement.
☑ Extended Meta’s Llama 3 model with multimodal projector, allowing direct audio input for faster responses compared to traditional ASR-LLM combinations, enhancing system efficiency.
☑ I evaluated the team projects and dedicated time to mentoring junior developers, fostering skill development and enhancing team performance.
☑ Implemented on a advanced RAG agent that ingest document context and provide assistant-like answers, improving user queries resolution.
☑ Designed real-time streaming pipeline for monitoring financial news, processing documents, and storing them in a vector database, enhancing data retrieval efficiency.
☑ Developed a serverless continuous training solution that fine-tunes an LLM on financial data, optimizing model performance through automatic tracking and registry saving.
☑ Built efficient batch prediction pipelines using Python, leveraing a Feature Store and GCS, orchestrated with Airflow, resulting in streamlined predictions and improved operational workflows.
Dana Scott Design, Indianapolis, United States
Full Stack AI Research Intern	02/2016 – 8/2017
☑ Started a career as a front-end developer and move to full stack position. 
☑ Translated Figma designs into user-friendly, reusable React components with high productivity and responsibility by leveraging proficiency in HTML/CSS and React-styled components. 
☑ Designed and implemented RESTful APIs, optimizing communication and dataflow for enhanced application functionality.
☑ Assisted in the development of transformer-based models for NLP tasks, contributing to early advancements in the field.
☑ Conducted experiments to evaluate model architectures, providing insights that guided future research directions.
☑ Collaborated with senior researchers to publish findings in academic conferences, gaining exposure to the research community.

- Certificates
Databricks Certified Data Engineer Associate 
Databricks - Issued Dec 2024
	Hands On Essentials - Data Warehouse
Snowflake - Issued Oct 2021
Microsoft Certified: Azure Data Fundamentals
Microsoft - Issued Oct 2021
	SnowPro Core Certification
Snowflake - Issued Oct 2021
dbt Fundamentals
dbt Labs - Issued Mar 2023	

- Education
Bachelor’s Degree in Mathematics                                                                                       University of Kansas (1/2009 – 4/2013)
        Master’s Degree in Computer Science                                                                                 University of Kansas (6/2013 – 9/2015)