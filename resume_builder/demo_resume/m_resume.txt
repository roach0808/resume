John Thomason
Senior AI/ML/MLOps Full Stack Engineer & Cloud Solution Architect & Agent Specialist & RAG Expert	NC, United State(US citizen)
thomasonjohn972@gmail.com
www.linkedin.com/in/john-thomason-26a9ab376
https://john-thomason-ai.vercel.app/
+18632130426

I am an ambitious Senior AI/ML Full Stack Engineer, with 10 years of experience in the Software Development industry. 
My passion for Artificial Intelligence research and Full Stack development ignited at its very beginning in America. Since then, I’ve been architecting, designing, and implementing top-of-the-line software solutions tailored to the unique needs of businesses. 
My commitment to staying at the forefront of technological advancements has enabled me to exceed the evolving demands of the digital business landscape. 
Fintech & Healthcare & Tech solution Industry Expertise
I have led end-to-end AI initiatives in both fintech and healthcare domains, bringing industry - specific context, regulatory awareness, and agentic intelligence into high-impact applications.
· Fintech: Built AI-powered credit decisioning pipelines, real-time scoring, and risk reduction systems. Implemented predictive analytics that transformed lender workflows, accelerating approvals and improving model precision with XGBoost and Scikit-learn frameworks.
· Healthcare: Architected multi-agent diagnostic and operations platforms integrated with EHRs, automating scheduling, patient intake, clinical workflows, and administrative tasks. These systems improved diagnostic accuracy, reduced clinician burden, and enhanced patient coordination.

- Technical Proficiencies

Languages:	Python, JavaScript, C++, Rust, C#, GoLang
Software Design Architecture:	FTI Architecture, batch serving architecture, online real-time pipeline, offline batch pipeline, asynchronous inference pipeline
AI Frameworks:	PyTorch, TensorFlow, Keras, Scikit-learn, XGBoost, langchain, Llama-index, Haystack, langGraph, AutoGen, Crew AI, Agentic Transformer, Transformer architecture, semantic Kernel
MLOps	GCP(Vertex AI, GCR, GKE, GCS, pub/sub), AWS(SageMaker, Fargate, lambda, S3 bucket, Databricks), Azure, W&B, DVC, Arize, Comet ML,Qwak, Databricks, MLFlow, Apache Spark
LLM:
	OpenAI, Anthropic, Azure, Llama-3,Mistral, Multi-modal LLM(TTS/STT/VST/AST), SDXL, Gemini,Vertex, Perplexity, Advanced RAG, TAG, Advanced chunking strategy, attention mechanisms, sequence-to-sequence models, encoder-decoder, BERT
Data Science:	     Pydantic, PySpark, Pandas, Polar, Ibis, BigQuery, MCP
Fullstack Development:	     Django, Flask, FastAPI, Express.JS, Node.js, PHP, React.JS, Next.JS
Database:
	PostgreSQL, MongoDB, Aurora DB, DynamoDB, Redis, Qdrant, SnowFlake, Hopsworks, PGVector, Pinecone, Milvus
Orchestrator:	Docker Swarm, ECS, K8s, Airflow, Kubeflow, ZenML, PipeDream
ORM:	Alchemy, Peewee, Django ORM
API Design Models:	REST API, RPC, GraphQL
CI/CD:	Git, GitLab, GitHub Actions, Jenkins, Kubernetes, CircleCI
Cloud Infrastructure Tools:	Terraform, Cloudformation, CDK, Pulumi
Streaming:	Apache Kafka, AWS Flink, Bytewax, CDC pattern, RabbitMQ, GCP pub/sub

- Career Experience
InsoftAI, FL, United State
Senior ML/MLOps Full Stack & AI-Agent Specialist & Solution Cloud Architect & RAG Expert	02/2023 – 08/2025
Focused on both fintech and healthcare client projects, delivering AI systems for financial risk assessment and 
healthcare process automation.
- Lead AI/Agent Engineer – Fintech-focused AI platform development 
· Partnered with Kilocode.ai to co-develop their open-source AI code copilot platform, delivering multi-agent support for architecting, writing, and debugging code directly inside the developer workflow and designed agentic workflows for modular code generation, enabling tools like auto-debugging, refactoring, and self-healing pipelines that adjust based on test outcomes and user intent.
· Integrated dynamic memory and context-awareness using MCP (Model Context Protocol) and Context‑7, significantly reducing LLM hallucinations and boosting user trust.
· Solved key growth challenges by building AI-powered analytic to optimize PPC campaign performance and automatically reallocate ad budgets to the highest-converting channels, improving ROAS by 35%.
· Engineered data pipelines to surface activation and retention patterns from platform usage data, helping Kilocode identify drop-off points and cohort-specific engagement gaps.
· Enabled multi-model support with Claude 4, GPT-4.1, and Gemini 2.5, with no config needed—driving higher adoption rates from non-technical users and reducing friction at on boarding.
· Co-authored growth dashboards that correlated user behavior with feature usage and retention, directly influencing product roadmap and GTM strategy.
· Integrated real-time metrics tracking into the code copilot platform to support user feedback loops, personalized prompts, and usage-based outreach campaigns.
· Supported community growth through strategic OSS contributions, inbound developer feedback loops, and continuous improvements that positioned Kilocode as a competitive alternative to GitHub Copilot and Cursor.
- AI/ML Focus + Product Impact
· Led the AI/ML Back-end architecture of xngen.app, building intelligent lead enrichment pipelines that combined LLM-driven summarization, business profiling, and automated outreach message generation.
· Integrated state-of-the-art language models to auto-generate personalized cold emails, subject lines, and intros tailored to a lead's company, domain, and role.
· Designed and deployed a real-time inference engine to process user-entered data (emails, domains, CSVs) and return enriched lead profiles in under 2 seconds, optimizing latency and API throughput.
· Developed custom data cleaning, deduplication, and entity resolution algorithms, boosting the accuracy of enriched contact data by over 35%.
· Engineered zero-friction user flows that converted cold input (emails, domains) into full-blown prospecting campaigns with AI-generated content, resulting in high activation rates.
· Built a multi-modal search engine (people, domain, company) with dynamic filters and scoring, enhancing precision in B2B lead targeting across various industries.
· Integrated CRM and email tools (like HubSpot, Gmail, and custom SMTP) using secure token-based APIs, enabling users to directly launch outreach campaigns from enriched data sets.
- LLM Twin: Personalized AI Outreach Agent/MLOps best practice for Scalable Lead Engagement
· Designed and developed “LLM Twin”, a personalized AI agent that mimics individual user tone, messaging style, and goals to autonomously generate high-conversion outreach content and built a persona-aware text generation pipeline leveraging prompt engineering, memory persistence, and retrieval-augmented generation (RAG) for deep contextual awareness.
· Integrated end-to-end TTS/STT pipelines into LLM Twin architecture using Whisper for domain-tuned speech recognition and FastSpeech 2 + HiFi-GAN for natural, real-time voice synthesis, enabling fully voice-driven LLM interaction with dynamic context tracking and audio fallback logic.
         · Integrated LLM orchestration tools (LangChain, OpenAI API) to support multi-agent pipelines, dynamic context injection, and scalable personalization for diverse user personas and enabled plug-and-play deployment for SaaS tools and CRM platforms, with an abstracted architecture for easy fine-tuning, cloning, and customization of LLM-based  agents.
         · Architected a low-latency, real-time inference pipeline for large language models by implementing a sequential request
processing system and adopting an online-first inference strategy, reducing average response times under tight SLAs.
· Designed a modular microservice architecture, splitting core ML services into a business logic REST API and an optimized LLM microservice, enabling dynamic scaling across various model sizes (e.g., Mistral, LLaMA, Falcon) with intelligent hardware utilization.
· Integrated advanced Graph RAG with Neo4j, enhancing pre-retrieval, retrieval, and post-retrieval stages using binary quantization, achieving up to 40x faster semantic search performance with improved answer accuracy.
· Deployed high-performance LLM inference infrastructure on AWS SageMaker using Hugging Face DLCs and the Text Generation Inference (TGI) engine, implementing flash attention, speculative decoding, safetensors, and continuous batching to achieve 2–4× speedups in token-level response latency.
· Developed a fine-tuning workflow using Unsloth, leveraging custom CUDA kernels for 2–5× faster training and up to 80% memory reduction, enabling cost-efficient adaptation of open-source LLMs for custom downstream tasks.
· Orchestrated full ML pipelines with ZenML and Airflow, containerizing applications with Docker, deploying on AWS EKS/ECS, and managing metadata/version control for reproducibility and observability.
· Implemented real-time Web-socket API layer in Fast-API, enabling live token-streaming interactions for agent-based systems and conversational AI experiences with sub-second round-trip latency.
· Built a robust evaluation and observability stack using Opik, Ragas, and ARES, combining trace visualizations, classifier-based QA metrics, and LLM-assisted assessments to optimize agentic workflows and iterate rapidly on model performance.
· Used advanced profiling tools on Kubernetes (Linux-based clusters) to uncover CPU, GPU, and I/O bottlenecks, leading to a 20% reduction in infra costs through precision optimization of compute-heavy pipelines.
- Healthcare CRM-Integrated Multimodal Multi-Agent Healthcare Assistant System
· Architected and deployed a multi-agent assistant platform for Doktor365, integrating roles like secretary, clinic admin, tourism guide, and pre-op coordinator with full CRM synchronization and built real-time, event-driven integration with healthcare CRM to allow agents to read/update patient data, appointment history, treatment stages, and lead status across workflows
· Enabled WhatsApp-based conversational intake and follow-ups, with automated agent responses logged directly into the CRM system for audit and handoff and developed memory-persistent agents with CRM context-awareness, allowing seamless continuity across voice, chat, and web interactions
· Orchestrated multi-agent logic using LangGraph with dynamic state transitions based on CRM data triggers (lead conversion, appointment updates, patient status) and reduced operational workload by over 70% by automating repetitive CRM tasks like patient onboarding, pre-op form collection, appointment reminders, and travel coordination
· Designed robust CRM-webhook pipelines to ensure real-time updates across agents and backend, improving patient experience and service coordination.
· Delivered a fully production-grade solution combining AI agents, CRM workflows, voice and text interfaces, and healthcare process automation at scale.
- Tamy AI: Real-Time Market Intelligence with Multi-Agent LLM System - LangGraph&Semantic Kernel
· Architected and deployed Tamy AI’s core AI assistant using LangGraph to power its lead-generation and market-intelligence platform, enabling stateful agent orchestration, contextual branching, and human-in-the-loop handoffs 
· Implemented real-time streaming interactions and persistent memory layers, allowing agents to recall prior queries, maintain context across sessions, and deliver personalized insights .
· Built robust error-handling, caching, and fallback mechanisms to ensure high uptime and reliability in production workflows .
· Integrated external data pipelines—including CRM enrichment, live contact data ingestion, and API-driven market intelligence—to power proactive and accurate B2B insights 
· Designed multi-agent workflows where specialized agents collaborate dynamically: routing intent, synthesizing data, summarizing results, and escalating human verification when needed .
· Leveraged LangSmith and LangGraph logging for full observability: tracked agent state transitions, prompt performance, drift, and conversational quality in production 
· Delivered the system at scale using containerized microservices and cloud-native infrastructure, enabling AI-powered lead delivery in real time to enterprise clients.

CoreWeave, Livingston, NJ
Senior AI/MLOps Engineer & Agent Developer	10/2019 – 12/2022
Led both healthcare agentic diagnosis and fintech analytic systems.
- Principal AI Architect – Healthcare Diagnostic Agent-Orchestrated Multimodal Diagnosis Platform
· Spearheaded the architecture and rollout of a multimodal, multi-agent AI system to automate cross-specialty medical diagnosis, 
transforming a traditionally manual, fragmented process into a real-time collaborative workflow.
· Engineered a team of autonomous specialist agents—covering dermatology, nephrology, cardiology, and more—each trained with 
fine-tuned LLMs and clinical protocols to deliver high-precision, specialty-aligned insights.
· Built real-time EHR integration pipelines to extract structured and unstructured data directly from patient records, enabling zero-latency diagnosis based on up-to-date medical histories.
· Designed a central orchestration agent to manage role-based task distribution, cross-agent communication, and aggregation of multidisciplinary findings into a unified, context-rich diagnosis file.
· Achieved 4x faster diagnostic turnaround and 92% accuracy in preliminary diagnosis generation, reducing cognitive load on human physicians and unlocking scalable expert collaboration.
· Developed a modular pipeline architecture with real-time validation, customization output formats, and long-term memory for tracking patient evolution across visits.
· Enabled hospital deployment with secure, containerized microservices and HIPAA-compliant data handling—laying the foundation for AI-powered triage and continuous care support systems.
- Sr. ML Engineer – Fintech Scalable AI-Powered Recommendation and RAG Systems
· I engineered a real-time personalized recommender system for H&M using TikTok-inspired architecture, deploying a two-tower model on Hopsworks AI Lakehouse to serve recommendations from a catalog of millions and designed and implemented a robust 4-stage recommender pipeline (candidate generation, filtering, ranking, re-ranking), enabling sub-second response times and contextual item matching at scale.
· Deployed query encoder and ranking services via KServe on Kubernetes with GPU autoscaling and canary rollouts, ensuring high availability and adaptive model performance in production, and integrated evaluation metrics like NDCG, Precision@K, Recall@K, and MRR to optimize relevance scoring, driving measurable improvements in user engagement and satisfaction.
· Built and deployed a real-time streaming pipeline for ingesting financial news, performing document embedding, and populating a vector DB for live data-driven recommendations and insights.  
· Implemented a fine-tuning pipeline using QLoRA and serverless training orchestration with experiment tracking and model registry integration, ensuring continuous learning and model evolution.  
· Delivered a production-grade inference system using LangChain, LangGraph, and LangSmith to enable multi-agent RAG/TAG-based question answering APIs over real-time financial knowledge graphs.
· Replaced traditional RAG with advanced KAG-based retrieval and reasoning, achieving 94%+ accuracy on popular science queries and a 20%+ improvement over legacy retrieval systems.
· Adopted full-stack MLOps practices with IaC, CI/CD pipelines, monitoring, and versioned experiment tracking, deploying a serverless, asynchronous architecture on AWS ECS/SQS that cut infrastructure costs by 52% while scaling on demand.
- Senior MLOps Engineer – Energy Forecasting Fintech Platform
· Led the architecture and deployment of a production-grade batch ML system to forecast hourly energy demand, enabling utility companies to optimize grid load balancing and reduce operational inefficiencies.
· Built and orchestrated scalable pipelines with Hopsworks, Airflow, and Docker, transforming volatile energy consumption data into structured, model-ready features with strict data validation, improving forecast reliability.
· Developed a model training and batch inference pipeline with W&B and GCP integration, automating experimentation and deployment cycles to deliver timely energy forecasts across all grid regions.
· Designed a user-facing analytics dashboard using FastAPI and Streamlit, equipping grid operators with real-time visibility into regional consumption trends, improving day-ahead planning accuracy by over 30%.
· Implemented CI/CD with GitHub Actions and containerized the full workflow using Poetry and Docker, accelerating release cycles and improving deployment repeatability across dev and prod environments.
· Addressed data drift and quality gaps using Great Expectations and custom validation checks, reducing downstream prediction failures and increasing model uptime during peak usage windows.

- Sr. ML Engineer – Second Brain AI Assistant
· Designed and deployed a Notion-style AI assistant leveraging Advanced RAG to enable smart content generation, summarization, and contextual Q&A across user notes, documents, and tasks.
· Implemented custom chunking strategies and metadata-aware embedding pipelines to enhance retrieval precision from unstructured workspace data stored in vector databases like Qdrant and PGVector, and built a personalized memory system combining long-term knowledge graphs with short-term context windows, allowing the assistant to deliver coherent multi-turn responses and project-specific insights.
· Integrated LangGraph-based agent orchestration with tool access for calendar lookups, task prioritization, and document editing—creating a fluid, multimodal AI collaborator and fine-tuned LLMs on workspace-specific datasets to adapt tone, voice, and formatting style, enhancing output quality for note-writing, meeting summaries, and documentation drafting
· Achieved 92%+ relevance in content retrieval and over 40% improvement in document answer accuracy by applying KAG (Knowledge-Augmented Generation) with multi-hop reasoning.
· Enabled real-time interaction through a RESTful API and WebSocket endpoints, with streaming token output and plugin integration for Notion-like UI platforms and adopted LLMOps best practices with automated evaluations, prompt monitoring, and continuous retraining pipelines—ensuring reliability and personalization at scale across user bases.
Kensho, Massachusetts, United State
Sr. Backend-heavy AI Developer	09/2017 – 09/2019
I worked on a TTS and STT solution, exposing it as an API that accurately clone voices from a short audio clip, significantly enhancing user experience in voice synthesis applications.
· Optimized training processes using distributed computing techniques, reducing training time by 5%.
· Collaborated with research teams to implement cutting-edge algorithms, enhancing the company's AI capabilities.
· I built an inference pipeline as a serverless RESTful API, enabling real-time financial question answering using BERT(Transformers), significantly improving user engagement.
· Extended Meta’s Llama 2 model with multi-modal projector, allowing direct audio input for faster responses compared to traditional ASR-LLM combinations, enhancing system efficiency.
· I evaluated the team projects and dedicated time to mentoring junior developers, fostering skill development and enhancing team performance.
· Implemented on a advanced Transformer agent that ingests document context and provides assistant-like answers, improving user queries resolution.
· Designed real-time streaming pipeline for monitoring financial news, processing documents, and storing them in a vector database, enhancing data retrieval efficiency.
· Developed a serverless continuous training solution that fine-tunes an LLM on financial data, optimizing model performance through automatic tracking and registry saving.
· Built efficient batch prediction pipelines using Python, leveraging a Feature Store and GCS, orchestrated with Airflow, resulting in streamlined predictions and improved operational workflows.
Dana Scott Design, Indianapolis, United States
Full Stack AI Research Intern	02/2016 – 8/2017
· Started a career as a front-end developer and moved to a full stack position. 
· Translated Figma designs into user-friendly, reusable React components with high productivity and responsibility by leveraging proficiency in HTML/CSS and React-styled components. 
· Designed and implemented RESTful APIs, optimizing communication and dataflow for enhanced application functionality.
· Assisted in the development of transformer-based models for NLP tasks, contributing to early advancements in the field.
· Conducted experiments to evaluate model architectures, providing insights that guided future research directions.
· Collaborated with senior researchers to publish findings in academic conferences, gaining exposure to the research community.


- Certificates
Databricks Certified Data Engineer Associate 
Databricks - Issued Dec 2024	Hands On Essentials - Data Warehouse
Snowflake - Issued Oct 2021
Microsoft Certified: Azure Data Fundamentals
Microsoft - Issued Oct 2021	SnowPro Core Certification
Snowflake - Issued Oct 2021
dbt Fundamentals
dbt Labs - Issued Mar 2023	

- Education
Bachelor’s Degree in Mathematics                                                                                       University of Kansas (2009 – 2013)
        Master’s Degree in Computer Science                                                                                 University of Kansas (2013 – 2015)